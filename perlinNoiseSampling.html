<!doctype html>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<html style=
    "background-color:rgb(16, 16, 16); 
    color:rgb(215, 215, 215); 
    margin-left: 2em; 
    font-family: verdana;">

    <body>
        <head>
            <title> Site Name. </title>
        </head>

        <h1>
            Using Perlin Noise to Sample Random Points
        </h1>

        <p>
            Most standard random number generators will, unless specified, output numbers which are <a href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution">uniformly distributed</a> over a specified range. This means all numbers within that range have an equal probability of being generated. If we were to plot the relative likelihood of each number being selected, we'd have what's known as the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a> or PDF of our distribution. In the case of a uniform distribution, this is simply a flat line.
        </p>

        <p>
            However, sometimes we'd like to bias our random numbers so that certain parts of our range are more or less likely to be sampled than others. This akin to sampling from a different, non-uniform PDF that more closely fits with our desired outcome. The <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a> for example is one such PDF that is widely known as it often arises in the real world in many different cases.???
        </p>

        <p>
            A common application of non-uniform distributions is in generating random points on the plane, where the probability of any point being selected is weighted according to some underlying noise function, like Perlin noise for instance. This is useful in the context of procedural generation since it allows us to do things such as distribute features in clusters.
        </p>

        <h2>
            Rejection Sampling
        </h2>

        <p>
            Probably the simplest way to achieve this is through <a href="https://en.wikipedia.org/wiki/Rejection_sampling">rejection sampling</a>. The process is as follows:
        </p>

        <p>
            While effective, this method can be quite slow when used with highly irregular probability distributions. In this case the number of rejected samples may be quite large, which amounts to a fair bit of wasted work. If we could sample from the desired PDF directly we could skip all that work entirely and get a correct result every time. Which brings us to...
        </p>

        <h2>
            Inverse Transform Sampling
        </h2>

        <p>
            As the name implies, <a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling">inverse transform sampling</a> is a transformation that maps a uniformly distributed random number to another number with a given PDF. On paper, the method is pretty simple. First we need an expression that describes our desired PDF. We'll use a simple quadratic bounded on \([-1, 1]\):
        </p>

        <p>
            $$ f(x) = 1 - x^2 $$
        </p>

        <p>
            Next, we need to derive the <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">cumulative distribution function</a> or CDF of our original PDF. The CDF represents the cumulative probability of a given number being selected, and can be found by taking the <a href="https://en.wikipedia.org/wiki/Antiderivative">antiderivative</a> of our PDF. The CDF \(F(x)\) of our quadratic function is thus:
        </p>

        <p>
            $$ \begin{aligned} F(x) &= \int_{-1}^x 1 - t^2 \,dt \\ &= x - \dfrac{x^3 - 2}{3} \end{aligned} $$
        </p>

        <h2>
            The CDF of Perlin Noise
        </h2>

    </body>
</html>